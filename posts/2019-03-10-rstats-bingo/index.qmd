---
title: "Statistics Bingo"
author: "Amanda Peterson"
date: 2019-03-10
categories: ["statistics","education"]
description: "Bingo for a statistics course"
image: "rstats_cookies.jpg"
---

I just wrapped up another round of teaching stats. I co-teach two courses per year as an adjunct instructor: one class that covers intro stats and the other that hits higher level concepts. Both courses move at a high pace; they're intended to be a survey course for professionals with a STEM background. Some students have a math background, but have never taken a statistics course. Other students have had statistics a long time ago in their undergraduate studies, but want to brush up on the material.

In both classes, by the time we get to the end, the students appreciate a light hearted activity. I found bingo to be the perfect activity to reveiew material and have a little fun. Jenny Bryan and Dean Attali have an [R Shiny app](https://daattali.com/shiny/bingo/) for creating such bingo games. Their site has a handful of pre-populated game themes such as "boring meeting" and "bad data". Or you can choose to create your own by pasting a list of words.

I created my own bingo questions that I ask during the game and answers that are written on the bingo cards. (Tip: Don't forget to bring the associated list of questions to class like I did!) I've pasted the questions and answers below that I used for each class.

Lastly, don't forget the sugar! M&M's make great bingo chips. And, cookies decorated with statsistics are a crowd pleaser.

![](rstats_cookies.jpg){fig-alt="cookies" fig-align="center"}

## Bingo Questions for Probability & Statistics I:

| Questions                                                                                                                                                                                                      | Answers                       |
|:-----------------------------------------------|------------------------|
| 1\. The R function used to find the area under the normal curve                                                                                                                                                | `pnorm`                       |
| 2\. For a discrete random variable: $E(X) = \sum_i^n X_i$ \* \_\_\_\_                                                                                                                                          | $P(X)$                        |
| 3\. Step 5 of the hypothesis testing method is to provide a conclusion in the \_\_\_\_\_.                                                                                                                      | context of the problem        |
| 4\. Square root of the variance                                                                                                                                                                                | standard deviation            |
| 5\. Mathematical function used to count number of possibilities: without replacement, order doesn't matter.                                                                                                    | choose                        |
| 6\. A \_\_\_ sample results when the population is divided into at least two different subpopulations based on some characteristic, and a sample is drawn from each subpopulation.                             | stratified                    |
| 7\. The Central Limit Theorem says that the distribution of the mean converges to this distribution as $n$ goes to infinity (variance must be defined).                                                        | normal                        |
| 8\. The \_\_\_\_ distribution approximates the Binomial when $n$ is large and $p$ is small. In this case we set $\lambda=np$.                                                                                  | Poisson                       |
| 9\. $P(A \cup B) = P(A) + P(B) -$ \_\_\_ ?                                                                                                                                                                     | $P(A \cap B)$                 |
| 10\. Discrete distribution that models the number of successes in $n$ Bernoulli trials, where $p$ is the probability of success.                                                                               | Binomial                      |
| 11\. The test statistic in the Test of Independence and The Goodness of Fit has a \_\_\_ distribution.                                                                                                         | Chi-Square                    |
| 12\. This distribution has PMF $P(X=k) = p^k(1-p)^{1-k}$                                                                                                                                                       | Bernoulli                     |
| 13\. Used to control the type I error of a hypothesis test                                                                                                                                                     | significance level ($\alpha$) |
| 14\. In hypothesis testing, we reject the null hypothesis if the test statistic falls in the \_\_\_\_ region.                                                                                                  | critical                      |
| 15\. Bayes Rule: $P(A \text{ given } B) =$ \_\_\_\_ \* $\frac{P(A)}{P(B)}$                                                                                                                                     | $P(B \text{ given } A)$       |
| 16\. The area under the entire PDF curve                                                                                                                                                                       | 1                             |
| 17\. The continuous distribution that looks like a bell curve (except that it has fat tails), converges to normal as $n$ increases, and is used when modeling data with small sample size.                     | Student's $t$                 |
| 18\. The maximum minus the minimum                                                                                                                                                                             | range                         |
| 19\. The most frequent observation in a data sample                                                                                                                                                            | mode                          |
| 20\. The function $F(X) = P(X \le x)$. You could describe it as a running total of the probability density function.                                                                                           | CDF                           |
| 21\. A \_\_\_ provides a range for which we are $(1-\alpha)$% confident contains the true value of the population parameter. In class we considered such ranges for the true mean, $\mu$, and for proportions. | confidence interval           |
| 22\. The \_\_\_ error occurs when the null hypothesis is true, but we reject it in favor of the alternative hypothesis.                                                                                        | Type I                        |
| 23\. The \_\_\_ of a hypothesis test is the probability that we reject the null hypothesis when it is in fact false.                                                                                           | power                         |
| 24\. $1 - P(A) =$ the probability of the \_\_\_ of $A$.                                                                                                                                                        | compliment                    |

## Bingo Questions for Probability & Statistics II:

| Questions                                                                                                                                                                                                                                                             | Answers                                       |
|:-----------------------------------------------|------------------------|
| 1\. Let {$X_i$} for $i=1..n$ partition the sample space. Bayes rule says that $f(X_i \text{ given } Y) = \frac{f(Y \text{ given } X_i)f(X_i)}{\sum_{i=1}^{n}f(Y \text{ given } X_i)f(X_i)}$. The \_\_\_ law is used in denominator when marginal, $f(Y)$, is unknown. | Law of Total Probability                      |
| 2\. Maximization of the log likelihood function (take derivative and set equal to 0)                                                                                                                                                                                  | MLE                                           |
| 3\. Probability density function for 2 or more variables                                                                                                                                                                                                              | Joint PDF                                     |
| 4\. Function used to count number of possibilities: without replacement, order doesn't matter                                                                                                                                                                         | choose                                        |
| 5\. Result of integrating $f(X,Y)$ with respect to $Y$, over the support of $Y$                                                                                                                                                                                       | marginal of $X$                               |
| 6\. An alternative to frequentist statistical analysis                                                                                                                                                                                                                | Bayesian statistics                           |
| 7\. CLT says that the distribution of the mean converges to this distribution as $n$ goes to infinity (variance must be defined)                                                                                                                                      | Normal                                        |
| 8\. $P(A \cap B) = P(A \text{ given } B)$ \* \_\_\_\_                                                                                                                                                                                                                 | $P(B)$                                        |
| 9\. Discrete distribution that models number of trials until 1 success                                                                                                                                                                                                | Geometric (special case of negative binomial) |
| 10\. Continuous distribution use to model time until events occur                                                                                                                                                                                                     | Gamma                                         |
| 11\. True or false: $Cov(X,Y)=0$ implies $X$ and $Y$ are independent. (TRUE if $X$ and $Y$ are jointly normally distributed. Independence implies $cov=0$ ).                                                                                                          | FALSE                                         |
| 12\. $E(XY) = E(X)E(Y)$ when X and Y are independent                                                                                                                                                                                                                  | TRUE                                          |
| 13\. $Var(X) = E(X^2) -$ \_\_\_\_                                                                                                                                                                                                                                     | $E(X)^2$                                      |
| 14\. $V(aX+b) =$ \_\_\_                                                                                                                                                                                                                                               | $a^2V(X)$                                     |
| 15\. Name of this function: $E(X^{tx})$ (Note: obtain $k^{th}$ moment by taking $k^{th}$ derivative and evaluating at $t$=0)                                                                                                                                          | Moment Generating Function                    |
| 16\. This distribution has PMF $P(X=k)= p^k(1-p)^{1-k}$                                                                                                                                                                                                               | Bernoulli                                     |
| 17\. Used in sampling from strata to ensure that the proportion of observations in the sample mimic the population proportions.                                                                                                                                       | Proportional allocation                       |
| 18\. Used to control the type I error of a hypothesis test                                                                                                                                                                                                            | Significance level ($\alpha$)                 |
| 19\. In Bayesian statistics, the population parameters are considered to be \_\_\_\_.                                                                                                                                                                                 | random variables                              |
| 20\. $P(A \text{ given } B) =$ \_\_\_\_ \* $\frac{P(A)}{P(B)}$                                                                                                                                                                                                        | $P(B \text{ given } A)$                       |
| 21\. $P(A \cup B) = P(A) + P(B)$ - \_\_\_\_\_\_                                                                                                                                                                                                                       | $P(A \cap B)$                                 |
| 22\. The area under the entire PDF curve                                                                                                                                                                                                                              | 1                                             |
| 23\. The derivative of the CDF with respect to the random variable (for a single random variable)                                                                                                                                                                     | PDF                                           |
| 24\. The second non-central moment                                                                                                                                                                                                                                    | Variance                                      |
| 25\. If $E(\hat{\theta}) = \theta$ we say $\hat{\theta}$ is \_\_\_.                                                                                                                                                                                                   | Unbiased                                      |
